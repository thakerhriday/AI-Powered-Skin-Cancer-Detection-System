{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd59767-75c2-4e95-8c7b-31c2d725c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9304e3c5-43da-4c18-966b-17fdf2adbd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>163</td>\n",
       "      <td>201</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>143</td>\n",
       "      <td>103</td>\n",
       "      <td>119</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>194</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        192        153        193        195        155        192   \n",
       "1         25         14         30         68         48         75   \n",
       "2        192        138        153        200        145        163   \n",
       "3         38         19         30         95         59         72   \n",
       "4        158        113        139        194        144        174   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "0        197        154        185        202  ...        173        124   \n",
       "1        123         93        126        158  ...         60         39   \n",
       "2        201        142        160        206  ...        167        129   \n",
       "3        143        103        119        171  ...         44         26   \n",
       "4        215        162        191        225  ...        209        166   \n",
       "\n",
       "   pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "0        138        183        147        166        185        154   \n",
       "1         55         25         14         28         25         14   \n",
       "2        143        159        124        142        136        104   \n",
       "3         36         25         12         17         25         12   \n",
       "4        185        172        135        149        109         78   \n",
       "\n",
       "   pixel2351  label  \n",
       "0        177      2  \n",
       "1         27      2  \n",
       "2        117      2  \n",
       "3         15      2  \n",
       "4         92      2  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\ishaa\\\\Desktop\\\\Hackathon\\\\hmnist_28_28_RGB.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0845c4-1ba3-4b4d-92a2-cf4630e001db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "4    6705\n",
      "6    1113\n",
      "2    1099\n",
      "1     514\n",
      "0     327\n",
      "5     142\n",
      "3     115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2e9eb1-54ba-415f-bc1d-115905bd2ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE (before binary conversion):\n",
      "label\n",
      "2    6705\n",
      "4    6705\n",
      "3    6705\n",
      "6    6705\n",
      "5    6705\n",
      "1    6705\n",
      "0    6705\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Apply SMOTE on the original multi-class labels\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Print class distribution BEFORE binary conversion\n",
    "print(\"Class distribution after SMOTE (before binary conversion):\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e02407a8-64fc-4a3c-92cf-cbf718fad5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after binary conversion:\n",
      "label\n",
      "0    26820\n",
      "1    20115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert multi-class labels to binary (Cancer = 1, Non-Cancer = 0)\n",
    "cancer_classes = {0, 1, 6}  # Define cancer-related classes\n",
    "y_resampled_binary = y_resampled.apply(lambda label: 1 if label in cancer_classes else 0)\n",
    "\n",
    "# Print class distribution AFTER binary conversion\n",
    "print(\"\\nClass distribution after binary conversion:\")\n",
    "print(pd.Series(y_resampled_binary).value_counts())\n",
    "\n",
    "# Create balanced dataset\n",
    "df_balanced = pd.concat([pd.DataFrame(X_resampled, columns=df.columns[:-1]), \n",
    "                         pd.DataFrame(y_resampled_binary, columns=[\"label\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a50454-4400-47f9-aa24-c7d189887367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>163</td>\n",
       "      <td>201</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>143</td>\n",
       "      <td>103</td>\n",
       "      <td>119</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>194</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        192        153        193        195        155        192   \n",
       "1         25         14         30         68         48         75   \n",
       "2        192        138        153        200        145        163   \n",
       "3         38         19         30         95         59         72   \n",
       "4        158        113        139        194        144        174   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "0        197        154        185        202  ...        173        124   \n",
       "1        123         93        126        158  ...         60         39   \n",
       "2        201        142        160        206  ...        167        129   \n",
       "3        143        103        119        171  ...         44         26   \n",
       "4        215        162        191        225  ...        209        166   \n",
       "\n",
       "   pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "0        138        183        147        166        185        154   \n",
       "1         55         25         14         28         25         14   \n",
       "2        143        159        124        142        136        104   \n",
       "3         36         25         12         17         25         12   \n",
       "4        185        172        135        149        109         78   \n",
       "\n",
       "   pixel2351  label  \n",
       "0        177      0  \n",
       "1         27      0  \n",
       "2        117      0  \n",
       "3         15      0  \n",
       "4         92      0  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d3d2ab-5498-418c-94d1-f0156e86f65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define binary class labels\n",
    "classes = {0: \"Benign\", 1: \"Malignant\"}\n",
    "\n",
    "# Extract pixel values (ignore the label column)\n",
    "X = df_balanced.iloc[:, :-1].values  # Exclude the last column (label)\n",
    "\n",
    "# Ensure correct reshaping\n",
    "num_images = X.shape[0]\n",
    "X = X.reshape(num_images, 28, 28, 3).astype(np.uint8)\n",
    "\n",
    "# Extract labels\n",
    "y = df_balanced.iloc[:, -1].values  # Get the last column (label)\n",
    "\n",
    "# Select 9 random images\n",
    "selected_indices = random.sample(range(num_images), 9)\n",
    "\n",
    "# Create a 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "\n",
    "for ax, idx in zip(axes.flat, selected_indices):\n",
    "    ax.imshow(X[idx])  # Display image\n",
    "    ax.set_title(classes[y[idx]])  # Use class label as title\n",
    "    ax.axis(\"off\")  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34a4a97-06c7-4d31-be71-ec20ccc5a689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5770 - loss: 0.6637 - val_accuracy: 0.6641 - val_loss: 0.5996\n",
      "Epoch 2/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6570 - loss: 0.5797 - val_accuracy: 0.7057 - val_loss: 0.5325\n",
      "Epoch 3/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7043 - loss: 0.5303 - val_accuracy: 0.7461 - val_loss: 0.4941\n",
      "Epoch 4/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.4974 - val_accuracy: 0.7742 - val_loss: 0.4633\n",
      "Epoch 5/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 0.4681 - val_accuracy: 0.7830 - val_loss: 0.4482\n",
      "Epoch 6/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 0.4519 - val_accuracy: 0.7965 - val_loss: 0.4292\n",
      "Epoch 7/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.4339 - val_accuracy: 0.8008 - val_loss: 0.4151\n",
      "Epoch 8/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4133 - val_accuracy: 0.7986 - val_loss: 0.4098\n",
      "Epoch 9/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.3970 - val_accuracy: 0.8199 - val_loss: 0.3877\n",
      "Epoch 10/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3843 - val_accuracy: 0.8231 - val_loss: 0.3835\n",
      "Epoch 11/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.3689 - val_accuracy: 0.8298 - val_loss: 0.3675\n",
      "Epoch 12/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 0.3536 - val_accuracy: 0.8459 - val_loss: 0.3442\n",
      "Epoch 13/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3468 - val_accuracy: 0.8465 - val_loss: 0.3315\n",
      "Epoch 14/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8509 - loss: 0.3327 - val_accuracy: 0.8433 - val_loss: 0.3362\n",
      "Epoch 15/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.3217 - val_accuracy: 0.8604 - val_loss: 0.3161\n",
      "Epoch 16/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.3112 - val_accuracy: 0.8628 - val_loss: 0.3088\n",
      "Epoch 17/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3010 - val_accuracy: 0.8626 - val_loss: 0.3056\n",
      "Epoch 18/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.2930 - val_accuracy: 0.8581 - val_loss: 0.3080\n",
      "Epoch 19/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2883 - val_accuracy: 0.8708 - val_loss: 0.2870\n",
      "Epoch 20/20\n",
      "\u001b[1m1174/1174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.2802 - val_accuracy: 0.8750 - val_loss: 0.2747\n",
      "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.2693 \n",
      "Test Accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training & testing (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Normalize pixel values (0 to 1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# CNN Model\n",
    "model = Sequential([\n",
    "    # Conv Layer 1\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Conv Layer 2\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # Flatten & Fully Connected Layers\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Prevent overfitting\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (0 = benign, 1 = malignant)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,  # Can increase for better accuracy\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b396187f-ee3c-4295-a390-b96687dd2504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m4,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m231\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">504,103</span> (1.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m504,103\u001b[0m (1.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">502,983</span> (1.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m502,983\u001b[0m (1.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120</span> (4.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,120\u001b[0m (4.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3,3), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(7,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c30ec9-411e-4911-a521-0172d4076012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c22ad31-a810-4a5d-b2c3-2244d52fe622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeadf87a-db0c-4310-9402-bd73d2ef3682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.5019 - loss: 1.5654 - val_accuracy: 0.4272 - val_loss: 2.1577\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8712 - loss: 0.3475 - val_accuracy: 0.8399 - val_loss: 0.3874\n",
      "Epoch 3/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9081 - loss: 0.2263 - val_accuracy: 0.8844 - val_loss: 0.3134\n",
      "Epoch 4/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9335 - loss: 0.1650 - val_accuracy: 0.9165 - val_loss: 0.2136\n",
      "Epoch 5/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9506 - loss: 0.1274 - val_accuracy: 0.9138 - val_loss: 0.2077\n",
      "Epoch 6/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9613 - loss: 0.1026 - val_accuracy: 0.7791 - val_loss: 0.8999\n",
      "Epoch 7/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9682 - loss: 0.0873 - val_accuracy: 0.7807 - val_loss: 1.0968\n",
      "Epoch 8/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9733 - loss: 0.0705 - val_accuracy: 0.8915 - val_loss: 0.3551\n",
      "Epoch 9/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9772 - loss: 0.0640 - val_accuracy: 0.8559 - val_loss: 0.4427\n",
      "Epoch 10/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9804 - loss: 0.0541 - val_accuracy: 0.8747 - val_loss: 0.4199\n",
      "Epoch 11/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9829 - loss: 0.0487 - val_accuracy: 0.9437 - val_loss: 0.1816\n",
      "Epoch 12/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9884 - loss: 0.0353 - val_accuracy: 0.9437 - val_loss: 0.1952\n",
      "Epoch 13/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9877 - loss: 0.0340 - val_accuracy: 0.7684 - val_loss: 1.1686\n",
      "Epoch 14/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9893 - loss: 0.0301 - val_accuracy: 0.9507 - val_loss: 0.1562\n",
      "Epoch 15/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9889 - loss: 0.0303 - val_accuracy: 0.9670 - val_loss: 0.1117\n",
      "Epoch 16/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9894 - loss: 0.0295 - val_accuracy: 0.9599 - val_loss: 0.1417\n",
      "Epoch 17/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9919 - loss: 0.0226 - val_accuracy: 0.8161 - val_loss: 1.0424\n",
      "Epoch 18/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9886 - loss: 0.0313 - val_accuracy: 0.8261 - val_loss: 0.7181\n",
      "Epoch 19/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9920 - loss: 0.0246 - val_accuracy: 0.8784 - val_loss: 0.4172\n",
      "Epoch 20/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9942 - loss: 0.0178 - val_accuracy: 0.9644 - val_loss: 0.1207\n",
      "Epoch 21/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9936 - loss: 0.0199 - val_accuracy: 0.9119 - val_loss: 0.3085\n",
      "Epoch 22/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9922 - loss: 0.0219 - val_accuracy: 0.9714 - val_loss: 0.1027\n",
      "Epoch 23/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9938 - loss: 0.0177 - val_accuracy: 0.9611 - val_loss: 0.1331\n",
      "Epoch 24/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9937 - loss: 0.0174 - val_accuracy: 0.9534 - val_loss: 0.1496\n",
      "Epoch 25/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9944 - loss: 0.0168 - val_accuracy: 0.9419 - val_loss: 0.2480\n",
      "Epoch 26/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9928 - loss: 0.0212 - val_accuracy: 0.9650 - val_loss: 0.1393\n",
      "Epoch 27/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.8867 - val_loss: 0.4325\n",
      "Epoch 28/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9931 - loss: 0.0187 - val_accuracy: 0.9736 - val_loss: 0.1094\n",
      "Epoch 29/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.9007 - val_loss: 0.3307\n",
      "Epoch 30/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9957 - loss: 0.0112 - val_accuracy: 0.9360 - val_loss: 0.2073\n",
      "Epoch 31/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9935 - loss: 0.0168 - val_accuracy: 0.9775 - val_loss: 0.1038\n",
      "Epoch 32/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9966 - loss: 0.0114 - val_accuracy: 0.9409 - val_loss: 0.2344\n",
      "Epoch 33/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 0.8667 - val_loss: 0.4067\n",
      "Epoch 34/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9944 - loss: 0.0174 - val_accuracy: 0.8927 - val_loss: 0.4351\n",
      "Epoch 35/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.9569 - val_loss: 0.1632\n",
      "Epoch 36/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9965 - loss: 0.0113 - val_accuracy: 0.9722 - val_loss: 0.1094\n",
      "Epoch 37/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9946 - loss: 0.0173 - val_accuracy: 0.9302 - val_loss: 0.2485\n",
      "Epoch 38/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9970 - loss: 0.0104 - val_accuracy: 0.9794 - val_loss: 0.0992\n",
      "Epoch 39/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9547 - val_loss: 0.1948\n",
      "Epoch 40/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9954 - loss: 0.0141 - val_accuracy: 0.9405 - val_loss: 0.2464\n",
      "Epoch 41/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9967 - loss: 0.0098 - val_accuracy: 0.9511 - val_loss: 0.2010\n",
      "Epoch 42/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9965 - loss: 0.0115 - val_accuracy: 0.9734 - val_loss: 0.1145\n",
      "Epoch 43/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.9510 - val_loss: 0.1962\n",
      "Epoch 44/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9954 - loss: 0.0129 - val_accuracy: 0.9715 - val_loss: 0.1095\n",
      "Epoch 45/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9977 - loss: 0.0071 - val_accuracy: 0.9105 - val_loss: 0.3888\n",
      "Epoch 46/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.9730 - val_loss: 0.1321\n",
      "Epoch 47/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.0069 - val_accuracy: 0.9394 - val_loss: 0.2424\n",
      "Epoch 48/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9390 - val_loss: 0.2694\n",
      "Epoch 49/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9969 - loss: 0.0106 - val_accuracy: 0.9447 - val_loss: 0.2440\n",
      "Epoch 50/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9672 - val_loss: 0.1462\n"
     ]
    }
   ],
   "source": [
    "Optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=128,\n",
    "                    epochs=50,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1c7c81a-58e5-4e0c-ae52-7715ce269a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"one.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5259c40d-7b2b-47ee-85f1-ef6c40a1a0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,817</span> (979.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,817\u001b[0m (979.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,985</span> (976.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m249,985\u001b[0m (976.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> (3.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m832\u001b[0m (3.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.6684 - loss: 0.6110 - val_accuracy: 0.7618 - val_loss: 0.4921\n",
      "Epoch 2/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8288 - loss: 0.3616 - val_accuracy: 0.7907 - val_loss: 0.4121\n",
      "Epoch 3/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8828 - loss: 0.2742 - val_accuracy: 0.7515 - val_loss: 0.5595\n",
      "Epoch 4/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9121 - loss: 0.2145 - val_accuracy: 0.8128 - val_loss: 0.3938\n",
      "Epoch 5/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9126 - loss: 0.2063 - val_accuracy: 0.8590 - val_loss: 0.3286\n",
      "Epoch 6/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.1572 - val_accuracy: 0.9361 - val_loss: 0.1531\n",
      "Epoch 7/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9507 - loss: 0.1261 - val_accuracy: 0.8977 - val_loss: 0.2350\n",
      "Epoch 8/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1146 - val_accuracy: 0.9559 - val_loss: 0.1154\n",
      "Epoch 9/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9619 - loss: 0.1003 - val_accuracy: 0.8687 - val_loss: 0.3520\n",
      "Epoch 10/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9661 - loss: 0.0877 - val_accuracy: 0.8264 - val_loss: 0.6730\n",
      "Epoch 11/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.0754 - val_accuracy: 0.8615 - val_loss: 0.3850\n",
      "Epoch 12/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9739 - loss: 0.0703 - val_accuracy: 0.9670 - val_loss: 0.0884\n",
      "Epoch 13/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9794 - loss: 0.0607 - val_accuracy: 0.8523 - val_loss: 0.4081\n",
      "Epoch 14/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9808 - loss: 0.0542 - val_accuracy: 0.9646 - val_loss: 0.1034\n",
      "Epoch 15/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9826 - loss: 0.0495 - val_accuracy: 0.9623 - val_loss: 0.1123\n",
      "Epoch 16/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0469 - val_accuracy: 0.9699 - val_loss: 0.0895\n",
      "Epoch 17/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0411 - val_accuracy: 0.9071 - val_loss: 0.3099\n",
      "Epoch 18/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0396 - val_accuracy: 0.9726 - val_loss: 0.0815\n",
      "Epoch 19/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0395 - val_accuracy: 0.9402 - val_loss: 0.1761\n",
      "Epoch 20/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0451 - val_accuracy: 0.9695 - val_loss: 0.0951\n",
      "Epoch 21/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0303 - val_accuracy: 0.9631 - val_loss: 0.1147\n",
      "Epoch 22/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0311 - val_accuracy: 0.9617 - val_loss: 0.1141\n",
      "Epoch 23/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9870 - loss: 0.0364 - val_accuracy: 0.9234 - val_loss: 0.2298\n",
      "Epoch 24/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0300 - val_accuracy: 0.9193 - val_loss: 0.2812\n",
      "Epoch 25/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0273 - val_accuracy: 0.9096 - val_loss: 0.2754\n",
      "Epoch 26/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0229 - val_accuracy: 0.8566 - val_loss: 0.5814\n",
      "Epoch 27/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0239 - val_accuracy: 0.8498 - val_loss: 0.4964\n",
      "Epoch 28/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9919 - loss: 0.0242 - val_accuracy: 0.9668 - val_loss: 0.1176\n",
      "Epoch 29/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0242 - val_accuracy: 0.9538 - val_loss: 0.1473\n",
      "Epoch 30/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0234 - val_accuracy: 0.9519 - val_loss: 0.1653\n",
      "Epoch 31/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0229 - val_accuracy: 0.9655 - val_loss: 0.1033\n",
      "Epoch 32/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.9495 - val_loss: 0.1605\n",
      "Epoch 33/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0203 - val_accuracy: 0.9744 - val_loss: 0.0829\n",
      "Epoch 34/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0192 - val_accuracy: 0.9672 - val_loss: 0.1088\n",
      "Epoch 35/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0140 - val_accuracy: 0.9609 - val_loss: 0.1252\n",
      "Epoch 36/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0162 - val_accuracy: 0.9631 - val_loss: 0.1270\n",
      "Epoch 37/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0185 - val_accuracy: 0.9724 - val_loss: 0.0852\n",
      "Epoch 38/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0209 - val_accuracy: 0.9525 - val_loss: 0.1570\n",
      "Epoch 39/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0195 - val_accuracy: 0.6503 - val_loss: 2.7202\n",
      "Epoch 40/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0209 - val_accuracy: 0.9788 - val_loss: 0.0782\n",
      "Epoch 41/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9679 - val_loss: 0.1159\n",
      "Epoch 42/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0175 - val_accuracy: 0.9557 - val_loss: 0.1509\n",
      "Epoch 43/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0130 - val_accuracy: 0.9364 - val_loss: 0.1835\n",
      "Epoch 44/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0107 - val_accuracy: 0.8722 - val_loss: 0.5454\n",
      "Epoch 45/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 0.9738 - val_loss: 0.0860\n",
      "Epoch 46/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0117 - val_accuracy: 0.9668 - val_loss: 0.1275\n",
      "Epoch 47/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 0.9708 - val_loss: 0.1191\n",
      "Epoch 48/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.9451 - val_loss: 0.2179\n",
      "Epoch 49/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0107 - val_accuracy: 0.9783 - val_loss: 0.0773\n",
      "Epoch 50/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.9567 - val_loss: 0.1529\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Conv Layer 3 (Optional, for deeper feature extraction)\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten and Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output Layer for Binary Classification (1 neuron + Sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))  # 1 neuron for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy',  # Use binary loss\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8c192da-1bde-4802-9b88-ad106077d39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,817</span> (979.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,817\u001b[0m (979.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,985</span> (976.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m249,985\u001b[0m (976.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> (3.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m832\u001b[0m (3.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.6694 - loss: 1.0431 - val_accuracy: 0.6582 - val_loss: 0.9068 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8150 - loss: 0.6367 - val_accuracy: 0.8353 - val_loss: 0.5419 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8682 - loss: 0.4737 - val_accuracy: 0.8015 - val_loss: 0.5787 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8797 - loss: 0.4358 - val_accuracy: 0.6738 - val_loss: 0.7741 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8967 - loss: 0.4080 - val_accuracy: 0.8810 - val_loss: 0.4305 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9090 - loss: 0.3764 - val_accuracy: 0.8590 - val_loss: 0.4705 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9210 - loss: 0.3548 - val_accuracy: 0.8518 - val_loss: 0.4852 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m938/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.3414\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9244 - loss: 0.3414 - val_accuracy: 0.8257 - val_loss: 0.5628 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9420 - loss: 0.2935 - val_accuracy: 0.8240 - val_loss: 0.5336 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.2426 - val_accuracy: 0.9515 - val_loss: 0.2576 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.2282 - val_accuracy: 0.9567 - val_loss: 0.2464 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9668 - loss: 0.2113 - val_accuracy: 0.9631 - val_loss: 0.2280 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9703 - loss: 0.2019 - val_accuracy: 0.8150 - val_loss: 0.6836 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.1957 - val_accuracy: 0.9304 - val_loss: 0.3093 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m933/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9749 - loss: 0.1843\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9748 - loss: 0.1843 - val_accuracy: 0.9216 - val_loss: 0.3181 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.1556 - val_accuracy: 0.9694 - val_loss: 0.2054 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.1370 - val_accuracy: 0.9636 - val_loss: 0.2199 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.1309 - val_accuracy: 0.9686 - val_loss: 0.2054 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m937/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.1258\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.1258 - val_accuracy: 0.9640 - val_loss: 0.2301 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.1120 - val_accuracy: 0.9751 - val_loss: 0.1908 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.1025 - val_accuracy: 0.9751 - val_loss: 0.1924 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0955 - val_accuracy: 0.9767 - val_loss: 0.1847 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0953 - val_accuracy: 0.9743 - val_loss: 0.2003 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0915 - val_accuracy: 0.9640 - val_loss: 0.2266 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m936/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0893\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0893 - val_accuracy: 0.9611 - val_loss: 0.2431 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0873 - val_accuracy: 0.9796 - val_loss: 0.1849 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m939/939\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0818 - val_accuracy: 0.9751 - val_loss: 0.2020 - learning_rate: 6.2500e-05\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 3), \n",
    "                 padding='same', kernel_regularizer=l2(0.001)))  # L2 Regularization\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same', \n",
    "                 kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Conv Layer 3 (Deeper feature extraction)\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same', \n",
    "                 kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten and Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  # Increased dropout\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Increased dropout\n",
    "\n",
    "# Output Layer for Binary Classification\n",
    "model.add(Dense(1, activation='sigmoid'))  # 1 neuron for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='binary_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks: Early Stopping & Learning Rate Scheduler\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, \n",
    "                    callbacks=[early_stop, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6b3bcf0-4388-4ac6-a382-0ee4b1e3ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f57c0c25-f0ef-4e47-8309-7faf7a326556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.1804 \n",
      "Test Loss: 0.1852\n",
      "Test Accuracy: 0.9757\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52eee3-a0ed-4d7a-aeb5-1347a487b363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
